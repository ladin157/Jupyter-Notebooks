{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-nearest neighbors\n",
    "\n",
    "The k-nearest neighbors test on iris data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some libraries are used listing below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import neighbors, datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load sampel data to test\n",
    "\n",
    "The dataset using is iris. ([more](https://en.wikipedia.org/wiki/Iris_flower_data_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 3\n",
      "Number of dat points: 150\n",
      "\n",
      "Samples from class 0: \n",
      " [[ 5.1  3.5  1.4  0.2]\n",
      " [ 4.9  3.   1.4  0.2]\n",
      " [ 4.7  3.2  1.3  0.2]\n",
      " [ 4.6  3.1  1.5  0.2]\n",
      " [ 5.   3.6  1.4  0.2]]\n",
      "\n",
      "Samples from class 1: \n",
      " [[ 7.   3.2  4.7  1.4]\n",
      " [ 6.4  3.2  4.5  1.5]\n",
      " [ 6.9  3.1  4.9  1.5]\n",
      " [ 5.5  2.3  4.   1.3]\n",
      " [ 6.5  2.8  4.6  1.5]]\n",
      "\n",
      "Samples from clas 2: \n",
      " [[ 6.3  3.3  6.   2.5]\n",
      " [ 5.8  2.7  5.1  1.9]\n",
      " [ 7.1  3.   5.9  2.1]\n",
      " [ 6.3  2.9  5.6  1.8]\n",
      " [ 6.5  3.   5.8  2.2]]\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "iris_X = iris.data\n",
    "iris_y = iris.target\n",
    "\n",
    "print('Number of classes: %d' %len(np.unique(iris_y)))\n",
    "print('Number of dat points: %d' %len(iris_y))\n",
    "\n",
    "X0 = iris_X[iris_y==0,:]\n",
    "print('\\nSamples from class 0: \\n', X0[:5,:])\n",
    "\n",
    "X1 = iris_X[iris_y==1,:]\n",
    "print('\\nSamples from class 1: \\n', X1[:5,:])\n",
    "\n",
    "X2 = iris_X[iris_y==2,:]\n",
    "print('\\nSamples from clas 2: \\n', X2[:5,:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seperate traing and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traing size: 100\n",
      "Test size: 50\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris_X, iris_y, test_size=50)\n",
    "\n",
    "print('Traing size: %d' %len(y_train))\n",
    "print('Test size: %d' %len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use k-nearest neighbors to predict the label of object in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result for whole datapoints in the test set: \n",
      "Predicted labels:  [1 0 2 2 2 1 1 1 0 0 2 0 2 1 1 2 0 0 0 1 0 2 2 1 1 1 2 0 1 0 2 2 1 0 0 1 0\n",
      " 0 2 1 2 1 2 1 1 2 2 2 2 2]\n",
      "Ground trutch:  [1 0 2 2 2 1 1 1 0 0 2 0 2 1 1 1 0 0 0 1 0 2 1 1 1 1 2 0 1 0 2 2 1 0 0 1 0\n",
      " 0 2 1 2 1 2 1 1 2 2 2 1 2]\n"
     ]
    }
   ],
   "source": [
    "n_neighbors = 5\n",
    "\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, p=2)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('The result for whole datapoints in the test set: ')\n",
    "print('Predicted labels: ', y_pred)\n",
    "print('Ground trutch: ', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of predicted process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of 5-NN is: 94.00 % \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('The accuracy of %d-NN is: %.2f %% ' %(n_neighbors, (100*accuracy_score(y_test, y_pred))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `k-nearest neighbors algorithm`\n",
    "\n",
    "The short overview of this algorithm, you can find on [wikipedia](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm) and the scientific paper [here](http://scholarpedia.org/article/K-nearest_neighbor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some things you need prepare to come to this task\n",
    "\n",
    "`(It is dedicated as suplement to whom who wants to go far in ML region, like author)`\n",
    "\n",
    "1. Metric distance\n",
    "2. k-nearest neghibor (one of simplest supervised machine learning algorithm `(like: Bayesian, K-NN, Regresion...)`)\n",
    "3. skcikit-learn: the powerful python libirary for machine learning.\n",
    "3. Programming skill (python is recommended)\n",
    "4. The other useful libraries: numpy, pandas, matplotlib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The last word\n",
    "\n",
    "Thank you for your attention. This is my first preparation in machine learning region, it must be contained somewhere a lot of errors. Your feedbacks are very helpful to me."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
